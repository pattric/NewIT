{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the libs and run through the functions before training or predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "np.random.seed(1)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    m = X.shape[0]                                   # number of training examples\n",
    "    X_indices = np.zeros([m, max_len])\n",
    "    \n",
    "    for i in range(m):                               # loop over training examples\n",
    "        sentence_words =X[i].lower().split()\n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            if w in word_to_index and j < max_len:\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "                j = j + 1\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_glove_vecs(file_path):\n",
    "    index_to_word = []\n",
    "    word_to_index = {}\n",
    "    word_to_vec_map = {}\n",
    "    index = 0\n",
    "    with open(file_path, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            l = line.split()\n",
    "            index_to_word.append(l[0])\n",
    "            word_to_index[l[0]] = index\n",
    "            word_to_vec_map[l[0]] = np.asarray(l[1:], dtype=np.float32)\n",
    "            index += 1\n",
    "    return word_to_index, index_to_word, word_to_vec_map\n",
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.first.3.rows.txt')\n",
    "# print(word_to_index, index_to_word, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    vocab_len = len(word_to_index) + 1                  # adding 1 to fit Keras embedding (requirement)\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      # define dimensionality of your GloVe word vectors (= 50\n",
    "    emb_matrix = np.zeros([vocab_len, emb_dim])\n",
    "    \n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "        \n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EAT_category_pred(input_shape, word_to_vec_map, word_to_index):\n",
    "    sentence_indices = Input(shape = input_shape, dtype = 'int32')\n",
    "    \n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    \n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    \n",
    "    X = LSTM(128, dropout=0.2, recurrent_dropout=0.2)(embeddings)\n",
    "    X = Dense(12)(X)\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    model = Model(inputs=sentence_indices, outputs=X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.read_excel(\"export.xlsx\", sheetname=None)\n",
    "df = dfs['EAI.TBLEVENT']\n",
    "all_events_list = \"ENVIRONMENTAL_EVENT\tPERSONALSAFETY_EVENT\tPROCESSSAFETY_EVENT\tRELIABILITY_EVENT\tSECURITY_EVENT\tQUALITY_EVENT\tAUDIT_EVENT\tASSESSMENT_EVENT\tBEHAVIORTRENDS_EVENT\tSUCCESSANALYSIS_EVENT\tOTHERLEARNINGEXPERIENCE_EV\tOTHERUNPLANNED_EVENT\".split(\"\t\")\n",
    "def get_sum_of_cat_per_row(row, event_list):\n",
    "    sum = 0\n",
    "    for event in event_list:\n",
    "        sum += row[event]\n",
    "    return -sum\n",
    "df['sum_of_categories'] = df.apply(lambda row: get_sum_of_cat_per_row(row, all_events_list), axis=1)\n",
    "plt.hist(df['sum_of_categories'], bins = [0, 1, 2, 3, 4, 5, 6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.loc[df['sum_of_categories'] == 1]\n",
    "df = df.sample(frac=1)\n",
    "df = df\n",
    "X_all = df['DESCRIPTION'].values.astype('U')\n",
    "Y_all = -df.loc[:, all_events_list].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['desc_len'] = df.apply(lambda row: len(str(row['DESCRIPTION']).split()), axis=1)\n",
    "plt.hist(df['desc_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxLen = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EAT_category_pred((maxLen,), word_to_vec_map, word_to_index)\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_ratio = 0.7\n",
    "split_index = int(train_data_ratio * len(X_all))\n",
    "X_train, Y_train, X_test, Y_test = X_all[0:split_index], Y_all[0:split_index], X_all[split_index:], Y_all[split_index:]\n",
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "# Y_train = convert_to_one_hot(Y_train, C = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_indices, Y_train, epochs = 10, batch_size = 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rand_indices = np.random.choice(19281, 5000)\n",
    "# X_test = X_all[rand_indices]\n",
    "# Y_test = Y_all[rand_indices]\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "loss, acc = model.evaluate(X_test_indices, Y_test)\n",
    "# loss, acc = model.evaluate(X_train_indices, Y_train)\n",
    "print(\"Test accuracy =\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_indices.shape\n",
    "model.predict(X_test_indices[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"keras-LSTM-1-layer-len80-acc7447.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the model directly from local disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"keras-LSTM-1-layer-len80-acc7447.h5\")\n",
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')\n",
    "max_len = 80\n",
    "all_events_list = \"ENVIRONMENTAL_EVENT\tPERSONALSAFETY_EVENT\tPROCESSSAFETY_EVENT\tRELIABILITY_EVENT\tSECURITY_EVENT\tQUALITY_EVENT\tAUDIT_EVENT\tASSESSMENT_EVENT\tBEHAVIORTRENDS_EVENT\tSUCCESSANALYSIS_EVENT\tOTHERLEARNINGEXPERIENCE_EV\tOTHERUNPLANNED_EVENT\".split(\"\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_category(model, desc, word_to_index, max_len, cat_list):\n",
    "    sentence_words = desc.lower().split()\n",
    "    sentence_indices = np.zeros(max_len)\n",
    "    j = 0\n",
    "    for w in sentence_words:\n",
    "        if w in word_to_index:\n",
    "            sentence_indices[j] = word_to_index[w]\n",
    "            j = j + 1\n",
    "        if j >= max_len:\n",
    "            break\n",
    "    sentence_indices = np.expand_dims(sentence_indices, axis=0)\n",
    "    probs = model.predict(sentence_indices)\n",
    "    index = np.argmax(probs)\n",
    "    return cat_list[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PERSONALSAFETY_EVENT'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc = \"First Aid- A worker fell while walking through parking lot\"\n",
    "pred_category(model, desc, word_to_index, max_len, all_events_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improvement ideas:\n",
    "* clean the data\n",
    "* get more data\n",
    "* change the hyperparameters (though not much difference with 1 or 2 LSTM layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
